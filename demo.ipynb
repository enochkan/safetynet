{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Plexiglass\n",
    "\n",
    "## LLM Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Conversation' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOUR_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf-conversational\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/DialoGPT-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuccess\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_injection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/cool_shit/kortex/plexiglass/plexiglass/LLM/evaluate.py:12\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, metrics, attacks)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attack \u001b[38;5;129;01min\u001b[39;00m attacks:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attack \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_injection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m         responses, prompts_used \u001b[38;5;241m=\u001b[39m \u001b[43mbasic_injection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompts_used, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m\"\u001b[39m: responses})\n\u001b[1;32m     15\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/cool_shit/kortex/plexiglass/plexiglass/LLM/attacks/injection/injection.py:12\u001b[0m, in \u001b[0;36mbasic_injection\u001b[0;34m(model, prompts_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line\u001b[38;5;241m.\u001b[39mstrip())[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m     prompts_used\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[0;32m---> 12\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, prompts_used\n",
      "File \u001b[0;32m~/Desktop/cool_shit/kortex/plexiglass/plexiglass/model.py:46\u001b[0m, in \u001b[0;36mModel.prompt\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversational\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;66;03m# wrap around hf's Conversation API\u001b[39;00m\n\u001b[1;32m     45\u001b[0m         user_msg \u001b[38;5;241m=\u001b[39m [Conversation(message) \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[0;32m---> 46\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_msg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Conversation' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "from plexiglass.LLM.evaluate import evaluate\n",
    "from plexiglass.model import Model\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "model = Model(\"hf-conversational\", \"microsoft/DialoGPT-small\")\n",
    "\n",
    "evaluate(model, metrics=[\"success\"], attacks=[\"prompt_injection\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
