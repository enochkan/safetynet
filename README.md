<h1>
<img src="plexiglass/assets/plexiglass.png" width="80" height="80"><br>
Plexiglass</h1>
<!-- <p align="center"> -->

[**Quickstart**](https://kortex-labs.github.io/plexiglass/build/html/quick-start.html) | [**Installation**](#installation) |
[**Documentation**](https://kortex-labs.github.io/plexiglass/build/html/index.html) | [**Code of Conduct**](#code-of-conduct)

<a href="https://badge.fury.io/py/plexiglass"><img src="https://badge.fury.io/py/plexiglass.svg" alt="PyPI version" height="18"></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-apache2.0-yellow.svg" alt="license MIT" height="18"></a>
</p>

Plexiglass is a toolkit for detecting and protecting against vulnerabilities in Large Language Models (LLMs).

Here's Plexiglass in action:
![alt](plexiglass/assets/demo_fast.gif)

## Installation

The first experimental release is version `0.0.1`.

To download the package from PyPi:

`pip install --upgrade plexiglass`

## Modes

Plexiglass can be used as a CLI tool as well as a standalone python lib (under development).

The CLI tool has two modes: `llm-chat` and `llm-scan`.

`llm-chat` allows you to converse with the LLM and measure predefined metrics, such as toxicity, from its responses.

`llm-scan` runs tests to identify and assess various vulnerabilities in the LLM.

## Feature Request
To request new features, please submit an [issue](https://github.com/enochkan/plexiglass/issues)

## Local Development

[Join us in #plexiglass on Discord.](https://discord.gg/RrH9fWP2)

## Contributors

<!-- Copy-paste in your Readme.md file -->

<a href="https://github.com/kortex-labs/plexiglass/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=kortex-labs/plexiglass" />
</a>

### Code of Conduct

Read our [Code of Conduct](https://kortex-labs.github.io/plexiglass/build/html/code-of-conduct.html).

Made with [contrib.rocks](https://contrib.rocks).
