<h1>
<img src="plexiglass/assets/plexiglass.png" width="80" height="80"><br>
Plexiglass</h1>
<!-- <p align="center"> -->

[**Quickstart**](#quickstart) | [**Installation**](#installation) |
[**Documentation**](https://kortex-labs.github.io/plexiglass/build/html/index.html) | [**Modes**](#modes) | [**Feature Request**](#feature-request)

<a href="https://badge.fury.io/py/plexiglass"><img src="https://badge.fury.io/py/plexiglass.svg" alt="PyPI version" height="18"></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-apache2.0-yellow.svg" alt="license MIT" height="18"></a>
</p>

## Quickstart

Plexiglass is a toolkit for detecting and protecting against vulnerabilities in Large Language Models (LLMs).

Simply [install](#Installation) and run `plx --help` to get started.

Here's a demo:
![alt](plexiglass/assets/demo_fast.gif)


> [!IMPORTANT]
> We are looking for contributors! Fork the repo to get started. Contribution guide is coming soon.

> [!NOTE]
> Plexiglass is open-source: Please leave a star to support the project! ‚≠ê

## Installation

The first experimental release is version `0.0.1`.

To download the package from PyPi:

`pip install --upgrade plexiglass`

## Modes

Plexiglass has two modes: `llm-chat` and `llm-scan`.

`llm-chat` allows you to converse with the LLM and measure predefined metrics, such as toxicity, from its responses.

`llm-scan` runs tests to identify and assess various vulnerabilities in the LLM.

## Feature Request
To request new features, please submit an [issue](https://github.com/enochkan/plexiglass/issues)

## Local Development

[Join us in #plexiglass on Discord.](https://discord.gg/RrH9fWP2)

## Contributors

<!-- Copy-paste in your Readme.md file -->

<a href="https://github.com/kortex-labs/plexiglass/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=kortex-labs/plexiglass" />
</a>

Made with [contrib.rocks](https://contrib.rocks).
